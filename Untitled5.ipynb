{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tK_iYo46AaP9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "fac = 5\n",
        "Mnist = tf.keras.datasets.mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear_Layer:\n",
        "\n",
        "    def __init__(self, in_dim, out_dim, alpha = 0.01, Theta = None, bias = None):\n",
        "        self.alpha = alpha\n",
        "        if Theta == None:\n",
        "            self.Theta = np.random.randn(in_dim, out_dim)/fac\n",
        "\n",
        "        else:\n",
        "            self.Theta = Theta\n",
        "\n",
        "        if bias == None:\n",
        "            self.bias = np.random.randn(out_dim)/fac\n",
        "\n",
        "        else:\n",
        "            self.bias = bias\n",
        "\n",
        "\n",
        "    def forward_pass(self, X):\n",
        "        self.X = X\n",
        "        self.z = np.matmul(X, self.Theta) + self.bias\n",
        "        return self.z\n",
        "\n",
        "\n",
        "    def backprop(self, grad_previous):\n",
        "        t= self.X.shape[0]\n",
        "        self.grad = np.matmul((self.X.transpose()), grad_previous)/t\n",
        "        self.grad_bias = (grad_previous.sum(axis=0))/t\n",
        "        self.grad_a = np.matmul(grad_previous, self.Theta.transpose())\n",
        "        return self.grad_a\n",
        "\n",
        "    def applying_sgd(self):\n",
        "            self.Theta = self.Theta - (self.alpha*self.grad)\n",
        "            self.bias = self.bias - (self.alpha*self.grad_bias)\n"
      ],
      "metadata": {
        "id": "3nEpTKm7DdTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class softmax:\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def expansion(self, t):\n",
        "        (a,) = t.shape\n",
        "        Y = np.zeros((a,10))\n",
        "        for i in range(0,a):\n",
        "            Y[i,t[i]] = 1\n",
        "        return Y\n",
        "\n",
        "    def forward_pass(self, z):\n",
        "        self.z =  z\n",
        "        (p,t) = self.z.shape\n",
        "        self.a = np.zeros((p,t))\n",
        "        for i in range(0,p):\n",
        "            for ii in range(0,t):\n",
        "                self.a[i,ii] = (np.exp(self.z[i,ii]))/(np.sum(np.exp(self.z[i,:])))\n",
        "        return self.a\n",
        "\n",
        "    def backprop(self, Y):\n",
        "        y = self.expansion(Y)\n",
        "        self.grad = (self.a - y)\n",
        "        return self.grad\n",
        "\n",
        "    def applying_sgd(self):\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "UYvjL3d4AeYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class relu:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward_pass(self, z):\n",
        "\n",
        "        if (len(z.shape) == 3):\n",
        "\n",
        "            z_temp = z.reshape((z.shape[0], z.shape[1]*z.shape[2]))\n",
        "            z_temp_1 = self.forward_pass(z_temp)\n",
        "            self.a_1 = z_temp_1.reshape((z.shape[0], z.shape[1], z.shape[2]))\n",
        "            return (self.a_1)\n",
        "\n",
        "        else:\n",
        "            (p,t) = z.shape\n",
        "            self.a = np.zeros((p,t))\n",
        "            for i in range(0,p):\n",
        "                for ii in range(0,t):\n",
        "                        self.a[i,ii] = max([0,z[i,ii]])\n",
        "            return self.a\n",
        "\n",
        "    def derivative(self, a):\n",
        "        if a>0:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def backprop(self, grad_previous):\n",
        "\n",
        "        if (len(grad_previous.shape)==3):\n",
        "\n",
        "            (d, p, t) = grad_previous.shape\n",
        "            self.grad = np.zeros((d, p, t))\n",
        "\n",
        "            for i in range(d):\n",
        "                for ii in range(p):\n",
        "                    for iii in range(t):\n",
        "                        self.grad[i, ii, iii] = (grad_previous[i, ii, iii] * self.derivative(self.a_1[i, ii, iii]))\n",
        "\n",
        "            return (self.grad)\n",
        "\n",
        "        else:\n",
        "            (p,t) = grad_previous.shape\n",
        "            self.grad = np.zeros((p,t))\n",
        "            for i in range(p):\n",
        "                for ii in range(t):\n",
        "                    self.grad[i,ii] = grad_previous[i,ii] * self.derivative(self.a[i,ii])\n",
        "            return (self.grad)\n",
        "\n",
        "\n",
        "    def applying_sgd(self):\n",
        "        pass\n",
        "\n"
      ],
      "metadata": {
        "id": "xPz5MAs8DysX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class padding():\n",
        "\n",
        "    def __init__(self, pad = 1):\n",
        "        self.pad = pad\n",
        "\n",
        "    def forward_pass(self, data):\n",
        "        X = np.pad(data , ((0, 0), (self.pad, self.pad), (self.pad, self.pad)),'constant', constant_values=0)\n",
        "        return X\n",
        "\n",
        "    def backprop(self, y):\n",
        "        return (y[:, 1:(y.shape[1]-1),1:(y.shape[2]-1)])\n",
        "\n",
        "    def applying_sgd(self):\n",
        "        pass\n",
        "\n"
      ],
      "metadata": {
        "id": "UW0WpkiEDyiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Convolutional_Layer:\n",
        "    def __init__(self, filter_dim = 3, stride = 1, pad = 1, alpha=0.01):\n",
        "        self.filter_dim = filter_dim\n",
        "        self.stride = stride\n",
        "        self.filter = np.random.randn(self.filter_dim, self.filter_dim)\n",
        "        self.filter = self.filter/self.filter.sum()\n",
        "        self.bias = np.random.rand()/10\n",
        "        self.pad = pad\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def convolving(self, X, fil, dimen_x, dimen_y):\n",
        "        z = np.zeros((dimen_x, dimen_y))\n",
        "        for i in range(dimen_x):\n",
        "            for ii in range(dimen_y):\n",
        "                temp = np.multiply(X[i : i+fil.shape[0], ii : ii+fil.shape[1]], fil)\n",
        "                z[i,ii] = temp.sum()\n",
        "        return z\n",
        "\n",
        "\n",
        "    def forward_pass(self, X):\n",
        "        self.X = X\n",
        "        (d, p, t) = self.X.shape\n",
        "        dimen_x = int(((p - self.filter_dim)/self.stride) + 1)\n",
        "        dimen_y = int(((t - self.filter_dim)/self.stride) + 1)\n",
        "        self.z = np.zeros((d, dimen_x, dimen_y))\n",
        "        for i in range(d):\n",
        "            self.z[i] = (self.convolving(self.X[i], self.filter, dimen_x, dimen_y) + self.bias)\n",
        "\n",
        "        return self.z\n",
        "\n",
        "    def backprop(self, grad_z):\n",
        "        (d, p, t) = grad_z.shape\n",
        "        filter_1 = np.flip((np.flip(self.filter, axis = 0)), axis = 1)\n",
        "        self.grads = np.zeros((d, p, t))\n",
        "        for i in range(d):\n",
        "            self.grads[i] = self.convolving(np.pad(grad_z[i], ((1,1), (1,1)), 'constant', constant_values = 0), filter_1, p, t)\n",
        "\n",
        "        self.grads = np.pad(self.grads, ((0,0),(1,1),(1,1)), 'constant', constant_values = 0)\n",
        "\n",
        "        self.grad_filter = np.zeros((self.filter_dim, self.filter_dim))\n",
        "\n",
        "        for i in range(self.filter_dim):\n",
        "            for ii in range(self.filter_dim):\n",
        "                self.grad_filter[i, ii] = (np.multiply(grad_z, self.X[:, i:p+i, ii:t+ii])).sum()\n",
        "        self.grad_filter = self.grad_filter/(d)\n",
        "\n",
        "        self.grad_bias = (grad_z.sum())/(d)\n",
        "        return self.grads\n",
        "\n",
        "    def applying_sgd(self):\n",
        "        self.filter = self.filter - (self.alpha*self.grad_filter)\n",
        "        self.bias = self.bias - (self.alpha*self.grad_bias)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MfBbTJRaDyej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class pooling:\n",
        "\n",
        "    def __init__(self, pool_dim = 2, stride = 2):\n",
        "        self.pool_dim = pool_dim\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward_pass(self, data):\n",
        "        (q, p, t) = data.shape\n",
        "        z_x = int((p - self.pool_dim) / self.stride) + 1\n",
        "        z_y = int((t - self.pool_dim) / self.stride) + 1\n",
        "        after_pool = np.zeros((q, z_x, z_y))\n",
        "        for ii in range(0, q):\n",
        "            liss = []\n",
        "            for i in range(0,p,self.stride):\n",
        "                for j in range(0,t,self.stride):\n",
        "                    if (i+self.pool_dim <= p) and (j+self.pool_dim <= t):\n",
        "                        temp = data[ii, i:(i+(self.pool_dim)), j:(j+(self.pool_dim))]\n",
        "                        temp_1 = np.max(temp)\n",
        "                        liss.append(temp_1)\n",
        "            liss = np.asarray(liss)\n",
        "            liss = liss.reshape((z_x, z_y))\n",
        "            after_pool[ii] = liss\n",
        "            del liss\n",
        "        return after_pool\n",
        "\n",
        "    def backprop(self, pooled):\n",
        "        (a,b,c) = pooled.shape\n",
        "        cheated = np.zeros((a,2*b,2*c))\n",
        "        for k in range(0, a):\n",
        "            pooled_transpose_re = pooled[k].reshape((b*c))\n",
        "            count = 0\n",
        "            for i in range(0, 2*b, self.stride):\n",
        "                for j in range(0, 2*c, self.stride):\n",
        "                    cheated[k, i:(i+(self.stride)),j:(j+(self.stride))] = pooled_transpose_re[count]\n",
        "                    count = count+1\n",
        "        return cheated\n",
        "\n",
        "    def applying_sgd(self):\n",
        "        pass\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qFrnbrdvDycD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Neural_Network:\n",
        "\n",
        "    def __init__(self, Network):\n",
        "        self.Network = Network\n",
        "\n",
        "    def forward_pass(self, X):\n",
        "        n = X\n",
        "        for i in self.Network:\n",
        "            n = i.forward_pass(n)\n",
        "\n",
        "\n",
        "        return n\n",
        "\n",
        "    def backprop(self, Y):\n",
        "        m = Y\n",
        "        count = 1\n",
        "        for i in (reversed(self.Network)):\n",
        "            m = i.backprop(m)\n",
        "\n",
        "    def applying_sgd(self):\n",
        "        for i in self.Network:\n",
        "            i.applying_sgd()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CxCXKtlfDyZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class reshaping:\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward_pass(self, a):\n",
        "        self.shape_a = a.shape\n",
        "\n",
        "        self.final_a = a.reshape(self.shape_a[0], self.shape_a[1]*self.shape_a[2])\n",
        "        return self.final_a\n",
        "\n",
        "    def backprop(self, q):\n",
        "        return (q.reshape(self.shape_a[0], self.shape_a[1], self.shape_a[2]))\n",
        "\n",
        "    def applying_sgd(self):\n",
        "        pass\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6AwbbjvYDyW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cross_entropy:\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def expansion(self, t):\n",
        "        (a,) = t.shape\n",
        "        Y = np.zeros((a,10))\n",
        "        for i in range(0,a):\n",
        "            Y[i,t[i]] = 1\n",
        "        return Y\n",
        "\n",
        "    def loss(self, A, Y):\n",
        "        exp_Y = self.expansion(Y)\n",
        "        (u,i) = A.shape\n",
        "        loss_matrix = np.zeros((u,i))\n",
        "        for j in range(u):\n",
        "            for jj in range(i):\n",
        "                if exp_Y[j,jj] == 0:\n",
        "                    loss_matrix[j,jj] = np.log(1 - A[j,jj])\n",
        "                else:\n",
        "                    loss_matrix[j,jj] = np.log(A[j,jj])\n",
        "\n",
        "\n",
        "        return ((-(loss_matrix.sum()))/u)\n",
        "\n"
      ],
      "metadata": {
        "id": "0VSkrXNDDyPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class accuracy:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def value(self, out, Y):\n",
        "        self.out = np.argmax(out, axis=1)\n",
        "        p = self.out.shape[0]\n",
        "        total = 0\n",
        "        for i in range(p):\n",
        "            if Y[i]==self.out[i]:\n",
        "                total += 1\n",
        "        return total/p\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jHVYr9uFEGUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "(Xtr, Ytr), (Xte, Yte) = Mnist.load_data()\n",
        "X_testing = Xtr[:,:,:]\n",
        "Y_testing = Ytr[:]\n",
        "#X_testing = X_testing.reshape((60000, 28*28))\n",
        "X_testing = X_testing/255\n",
        "al = 0.5\n",
        "stopper = 25.0\n",
        "\n",
        "complete_NN = Neural_Network([\n",
        "\n",
        "                                padding(),\n",
        "                                Convolutional_Layer(),\n",
        "                                pooling(),\n",
        "                                relu(),\n",
        "                                padding(),\n",
        "                                Convolutional_Layer(),\n",
        "                                pooling(),\n",
        "                                relu(),\n",
        "                                reshaping(),\n",
        "                                Linear_Layer(7*7, 24, alpha = al),\n",
        "                                relu(),\n",
        "                                Linear_Layer(24, 10, alpha = al),\n",
        "                                softmax()\n",
        "\n",
        "                                ])\n",
        "CE = cross_entropy()\n",
        "\n",
        "acc = accuracy()\n",
        "epochs = 50\n",
        "broke = 0\n",
        "batches = 6000\n",
        "for i in range(epochs):\n",
        "    k = 0\n",
        "    for ii in range(batches, 60001, batches):\n",
        "\n",
        "        out = complete_NN.forward_pass(X_testing[k:ii])\n",
        "        print(\"epoch:{} \\t batch: {} \\t loss: \\t {}\".format(i+1, int(ii/batches), CE.loss(out, Y_testing[k:ii])), end=\"\\t\")\n",
        "        accur = acc.value(out, Y_testing[k:ii])*100\n",
        "        print(\"accuracy: {}\".format(accur))\n",
        "\n",
        "        if accur >= stopper:\n",
        "            broke = 1\n",
        "            break\n",
        "        complete_NN.backprop(Y_testing[k:ii])\n",
        "        complete_NN.applying_sgd()\n",
        "        k = ii\n",
        "\n",
        "    if broke == 1:\n",
        "        break\n",
        "\n",
        "\n",
        "out = complete_NN.forward_pass(X_testing)\n",
        "print(\"The final loss is {}\".format(CE.loss(out, Y_testing)))\n",
        "print(\"The final accuracy on train set is {}\".format(acc.value(out, Y_testing)*100))\n",
        "Xtest = Xte/255\n",
        "#Xtest = Xte.reshape((10000,28*28))/255\n",
        "out_1 = complete_NN.forward_pass(Xtest)\n",
        "print(\"The accuracy on test set is {}\".format(acc.value(out_1, Yte)*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouE4iCsXEGRv",
        "outputId": "7fdef889-5d03-4d91-e3d3-b16b9612daaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1 \t batch: 1 \t loss: \t 3.7622215477836343\taccuracy: 10.233333333333333\n",
            "epoch:1 \t batch: 2 \t loss: \t 3.3307235737932674\taccuracy: 8.6\n",
            "epoch:1 \t batch: 3 \t loss: \t 3.174368602028808\taccuracy: 16.03333333333333\n",
            "epoch:1 \t batch: 4 \t loss: \t 3.0923706452607234\taccuracy: 20.849999999999998\n",
            "epoch:1 \t batch: 5 \t loss: \t 2.985563322967745\taccuracy: 25.883333333333336\n",
            "The final loss is 2.9900995480962798\n",
            "The final accuracy on train set is 25.27\n",
            "The accuracy on test set is 25.169999999999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gVEcSg48EGPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iiDheqHvEGM2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}